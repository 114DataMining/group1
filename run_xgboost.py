import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import numpy as np

# è¨­å®šä¸å½ˆå‡ºè¦–çª—ï¼Œç›´æ¥ç¹ªåœ–è‡³å¾Œå°
import matplotlib
matplotlib.use('Agg') 

# ===============================
# 1. è®€å–è³‡æ–™
# ===============================
try:
    df = pd.read_csv("diabetes_skinthickness_knn_imputed.csv")
    print(f"âœ… è³‡æ–™è®€å–æˆåŠŸï¼æ¨£æœ¬ç¸½æ•¸: {len(df)}")
except FileNotFoundError:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆã€‚")

target = "Outcome"
X = df.drop(columns=[target])
y = df[target]

# ===============================
# 2. åˆ‡åˆ†è¨“ç·´é›† (80%, ç´„592ç­†) èˆ‡æ¸¬è©¦é›† (20%, ç´„148ç­†)
# ===============================
X_train_all, X_test, y_train_all, y_test = train_test_split(
    X, y,
    test_size=0.20, 
    stratify=y,
    random_state=42
)

# ===============================
# 3. åŸ·è¡Œ Grid Search å„ªåŒ–
# ===============================
param_grid = {
    'max_depth': [2, 3],
    'min_child_weight': [10, 11, 12],
    'learning_rate': [0.01, 0.05, 0.08],
    'subsample': [0.6, 0.7, 0.8],
    'gamma': [1, 2],
    'reg_lambda': [5, 10],
    'n_estimators': [100, 150, 200]
}

scoring = {'AUC': 'roc_auc', 'Accuracy': 'accuracy', 'F1': 'f1'}
ratio = sum(y_train_all == 0) / sum(y_train_all == 1)

xgb_base = xgb.XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=ratio,
    random_state=42,
    n_jobs=-1,
    eval_metric='logloss'
)

cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("\n===== æ­£åœ¨é€²è¡Œ Grid Search å„ªåŒ–åƒæ•¸... =====")
grid_search = GridSearchCV(
    estimator=xgb_base,
    param_grid=param_grid,
    scoring=scoring,
    refit='AUC',
    cv=cv_strategy,
    n_jobs=-1,
    return_train_score=True
)
grid_search.fit(X_train_all, y_train_all)

best_params = grid_search.best_params_
print(f"\nğŸ† æœ€ä½³åƒæ•¸çµ„åˆ: {best_params}")

# ===============================
# 4. ç¹ªè£½ 5-Fold ROC ä¸¦çµ±è¨ˆé¡åˆ¥æ•¸é‡
# ===============================
plt.figure(figsize=(10, 8))
plt.rcParams["font.sans-serif"] = ["Microsoft JhengHei"]
plt.rcParams["axes.unicode_minus"] = False

tprs = []
mean_fpr = np.linspace(0, 1, 100)

print("\n" + "="*60)
print(f"{'æŠ˜æ•¸':<4} | {'è¨“ç·´é›† (0/1)':<15} | {'é©—è­‰é›† (0/1)':<15} | {'Train AUC':<10} | {'Val AUC':<10}")
print("-" * 60)

for i, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train_all, y_train_all)):
    X_tr, X_va = X_train_all.iloc[train_idx], X_train_all.iloc[val_idx]
    y_tr, y_va = y_train_all.iloc[train_idx], y_train_all.iloc[val_idx]
    
    # çµ±è¨ˆé¡åˆ¥å€‹æ•¸
    tr_0, tr_1 = (y_tr == 0).sum(), (y_tr == 1).sum()
    va_0, va_1 = (y_va == 0).sum(), (y_va == 1).sum()
    
    model = xgb.XGBClassifier(**best_params, scale_pos_weight=ratio, random_state=42, eval_metric='logloss')
    model.fit(X_tr, y_tr)
    
    # æŒ‡æ¨™è¨ˆç®—
    y_prob_va = model.predict_proba(X_va)[:, 1]
    fpr, tpr, _ = roc_curve(y_va, y_prob_va)
    roc_auc_va = auc(fpr, tpr)
    
    y_prob_tr = model.predict_proba(X_tr)[:, 1]
    roc_auc_tr = roc_auc_score(y_tr, y_prob_tr)
    
    # è¼¸å‡ºæ ¼å¼åŒ–çµæœ
    print(f"Fold {i+1:<1} | {tr_0:>3}/{tr_1:<3}        | {va_0:>3}/{va_1:<3}        | {roc_auc_tr:.4f}    | {roc_auc_va:.4f}")
    
    plt.plot(fpr, tpr, lw=1, alpha=0.5, label=f'Fold {i+1} Val (AUC = {roc_auc_va:.3f})')
    
    interp_tpr = np.interp(mean_fpr, fpr, tpr)
    interp_tpr[0] = 0.0
    tprs.append(interp_tpr)

print("="*60)

# ç¹ªè£½å¹³å‡ç·šèˆ‡æ¸¬è©¦é›†
mean_tpr = np.mean(tprs, axis=0)
plt.plot(mean_fpr, mean_tpr, color='blue', label=f'Mean CV Val ROC (AUC = {auc(mean_fpr, mean_tpr):.3f})', lw=2)

xgb_final = grid_search.best_estimator_
y_test_prob = xgb_final.predict_proba(X_test)[:, 1]
fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)
plt.plot(fpr_test, tpr_test, color='red', label=f'Final Test ROC (AUC = {auc(fpr_test, tpr_test):.3f})', lw=3, linestyle='--')

plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title('XGBoost è¨“ç·´é€²åº¦èˆ‡æ¨£æœ¬åˆ†ä½ˆåˆ†æ')
plt.legend(loc="lower right")
plt.savefig("roc_with_class_counts.png", dpi=300)
plt.close()

# ===============================
# 5. è¼¸å‡ºæœ€çµ‚æ•ˆèƒ½å ±è¡¨
# ===============================
best_idx = grid_search.best_index_
res = grid_search.cv_results_

# æœ€çµ‚æ¸¬è©¦é›†çµ±è¨ˆ
te_0, te_1 = (y_test == 0).sum(), (y_test == 1).sum()
y_test_pred = (y_test_prob > 0.5).astype(int)

print("\n" + "="*40)
print(f"ğŸ“Š æœ€çµ‚æ¸¬è©¦é›†æ¨£æœ¬åˆ†ä½ˆ (n={len(y_test)})")
print(f"0 (å¥åº·): {te_0} ç­† | 1 (æ‚£ç—…): {te_1} ç­†")
print("-" * 40)
print(f"æ¸¬è©¦é›† AUC: {roc_auc_score(y_test, y_test_prob):.4f}")
print(f"æ¸¬è©¦é›† Accuracy: {accuracy_score(y_test, y_test_pred):.4f}")
print(f"æ¸¬è©¦é›† F1-Score: {f1_score(y_test, y_test_pred):.4f}")
print("="*40)

print("\nçµ±è¨ˆåœ–è¡¨èˆ‡æ•¸æ“šå·²å­˜è‡³: roc_with_class_counts.png")
# ===============================
# 6. ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Importance)
# ===============================
# å–å¾—ç‰¹å¾µåç¨±èˆ‡åˆ†æ•¸
importances = xgb_final.feature_importances_
feature_names = X.columns

# å»ºç«‹ DataFrame ä¸¦æ’åº
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=True) # ç”±å°åˆ°å¤§æ’ï¼Œæ–¹ä¾¿æ©«å‘åœ–ç”±ä¸Šåˆ°ä¸‹é¡¯ç¤º

# ç¹ªåœ–
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.title('XGBoost ç‰¹å¾µé‡è¦æ€§åˆ†æ (Feature Importance)')
plt.grid(axis='x', linestyle='--', alpha=0.7)

# åœ¨é•·æ¢åœ–ä¸Šæ¨™è¨»æ•¸å€¼
for index, value in enumerate(feature_importance_df['Importance']):
    plt.text(value, index, f'{value:.4f}')

plt.tight_layout()
plt.savefig("feature_importance.png", dpi=300)
print("\nç‰¹å¾µé‡è¦æ€§åœ–è¡¨å·²å­˜è‡³: feature_importance.png")

# é¡å¤–è¼¸å‡ºæ–‡å­—ç‰ˆæ¸…å–®ï¼ˆç”±é«˜åˆ°ä½ï¼‰
print("\nç‰¹å¾µé‡è¦æ€§æ’å:")
print("-" * 30)
print(feature_importance_df.sort_values(by='Importance', ascending=False).to_string(index=False))
print("-" * 30)